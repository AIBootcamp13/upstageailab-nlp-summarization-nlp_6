"""
ëŒ€í™” ìš”ì•½ ëª¨ë¸ í•™ìŠµ/ì¶”ë¡  íŒŒì´í”„ë¼ì¸
ëª¨ë“ˆí™”ëœ êµ¬ì¡°ë¡œ ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
"""

import argparse
import sys
import os
from datetime import datetime

# íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ import
from pipeline import (
    ConfigManager,
    create_optimized_config_for_rtx3060,
    DataProcessor,
    TrainingManager,
    ModelManager,
    InferenceManager,
    InteractiveInference,
    KFoldManager
)
from pipeline.config_manager import (
    create_high_quality_config_for_rtx3060,
    create_balanced_config_for_rtx3060,
    create_kfold_config_for_rtx3060,
    create_kfold_config_for_high_performance,
    create_fast_kfold_config_for_rtx3060,
    create_rtx3090_baseline_config,
    create_rtx3090_baseline_kfold_config,
    create_rtx3090_baseline_fast_config
)


def generate_model_output_path(config):
    """ëª¨ë¸ ì¶œë ¥ ê²½ë¡œ ìƒì„± (ëª¨ë¸ëª… + íƒ€ì„ìŠ¤íƒ¬í”„)"""
    # ëª¨ë¸ëª…ì—ì„œ ê²½ë¡œì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
    model_name = config['general']['model_name']
    safe_model_name = model_name.replace('/', '_').replace('\\', '_')

    # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # í´ë”ëª… ìƒì„±: ëª¨ë¸ëª…_íƒ€ì„ìŠ¤íƒ¬í”„
    folder_name = f"{safe_model_name}_{timestamp}"

    # ì „ì²´ ê²½ë¡œ ìƒì„±
    base_output_dir = config['general'].get('output_dir', './model_output/')
    model_output_path = os.path.join(base_output_dir, folder_name)

    return model_output_path


def setup_config(args):
    """ì„¤ì • ì´ˆê¸°í™”"""
    print("=" * 80)
    print("ì„¤ì • ì´ˆê¸°í™”")
    print("=" * 80)

    config_manager = ConfigManager(args.config)

    if args.create_config:
        if args.kfold_rtx3060:
            print(
                f"RTX 3060 K-Fold êµì°¨ ê²€ì¦ ì„¤ì • ìƒì„± ì¤‘... ({args.kfold_splits} folds)")
            config = create_kfold_config_for_rtx3060(
                n_splits=args.kfold_splits,
                ensemble_method=args.ensemble_method
            )
        elif args.kfold_high_performance:
            print(
                f"ê³ ì„±ëŠ¥ GPU K-Fold êµì°¨ ê²€ì¦ ì„¤ì • ìƒì„± ì¤‘... ({args.kfold_splits} folds)")
            config = create_kfold_config_for_high_performance(
                n_splits=args.kfold_splits,
                ensemble_method=args.ensemble_method
            )
        elif args.fast_kfold_rtx3060:
            print(f"RTX 3060 ë¹ ë¥¸ K-Fold ì„¤ì • ìƒì„± ì¤‘... ({args.kfold_splits} folds)")
            config = create_fast_kfold_config_for_rtx3060(
                n_splits=args.kfold_splits,
                ensemble_method=args.ensemble_method
            )
        elif args.high_quality_rtx3060:
            print("RTX 3060 ê³ í’ˆì§ˆ ì„¤ì • ìƒì„± ì¤‘... (Final Score ìµœëŒ€í™”)")
            config = create_high_quality_config_for_rtx3060()
        elif args.balanced_rtx3060:
            print("RTX 3060 ê· í˜• ì„¤ì • ìƒì„± ì¤‘... (ì†ë„ì™€ í’ˆì§ˆ ê· í˜•)")
            config = create_balanced_config_for_rtx3060()
        elif args.rtx3090_baseline:
            print("RTX 3090 Baseline ì„¤ì • ìƒì„± ì¤‘... (baseline.ipynb ê¸°ë°˜)")
            config = create_rtx3090_baseline_config()
        elif args.rtx3090_baseline_kfold:
            print(f"RTX 3090 Baseline + K-Fold ì„¤ì • ìƒì„± ì¤‘... ({args.kfold_splits} folds)")
            config = create_rtx3090_baseline_kfold_config(
                n_splits=args.kfold_splits,
                ensemble_method=args.ensemble_method
            )
        elif args.rtx3090_baseline_fast:
            print("RTX 3090 ë¹ ë¥¸ Baseline ì„¤ì • ìƒì„± ì¤‘... (ì‹¤í—˜ìš©)")
            config = create_rtx3090_baseline_fast_config()
        elif args.optimize_rtx3060:
            print("RTX 3060 ê¸°ë³¸ ìµœì í™” ì„¤ì • ìƒì„± ì¤‘...")
            config = create_optimized_config_for_rtx3060()
        else:
            print("ê¸°ë³¸ ì„¤ì • ìƒì„± ì¤‘...")
            config_data = config_manager.create_default_config(
                model_name=args.model_name or "digit82/kobart-summarization",
                data_path=args.data_path or "../advanced_processed_data/"
            )
            config_manager.save_config(config_data)
            config = config_manager.load_config()
    else:
        config = config_manager.load_config()

    # ëª…ë ¹í–‰ ì¸ìë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if args.model_name:
        config['general']['model_name'] = args.model_name
    if args.data_path:
        config['general']['data_path'] = args.data_path
        # ì¦ê°• ë°ì´í„° í´ë”ì¸ì§€ ìë™ ê°ì§€
        if os.path.basename(args.data_path).startswith('augmented_'):
            print(f"ğŸ” ì¦ê°• ë°ì´í„° í´ë” ê°ì§€: {os.path.basename(args.data_path)}")
    if args.output_dir:
        config['general']['output_dir'] = args.output_dir
    if args.epochs:
        config['training']['num_train_epochs'] = args.epochs
    if args.batch_size:
        config['training']['per_device_train_batch_size'] = args.batch_size
        config['training']['per_device_eval_batch_size'] = args.batch_size
    if args.learning_rate:
        config['training']['learning_rate'] = args.learning_rate

    # í•™ìŠµ ëª¨ë“œì¸ ê²½ìš° íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ì¶œë ¥ ê²½ë¡œ ìƒì„±
    if args.mode == 'train':
        model_output_path = generate_model_output_path(config)
        config['general']['output_dir'] = model_output_path
        config['training']['output_dir'] = model_output_path
        config['training']['logging_dir'] = os.path.join(
            model_output_path, 'logs')
        config['inference']['ckt_path'] = model_output_path

        print(f"\nğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_output_path}")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(model_output_path, exist_ok=True)
        os.makedirs(os.path.join(model_output_path, 'logs'), exist_ok=True)

    config_manager.print_config()
    return config


def save_training_info(config):
    """í•™ìŠµ ì •ë³´ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    output_dir = config['general']['output_dir']

    # í•™ìŠµ ì •ë³´ ìˆ˜ì§‘
    training_info = {
        'model_name': config['general']['model_name'],
        'data_path': config['general']['data_path'],
        'training_start_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'training_config': config['training'],
        'tokenizer_config': config['tokenizer'],
        'hardware_info': config['general'].get('hardware', 'unknown'),
        'lora_config': config.get('lora', {}),
    }

    # JSON íŒŒì¼ë¡œ ì €ì¥
    import json
    info_file = os.path.join(output_dir, 'training_info.json')
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(training_info, f, ensure_ascii=False, indent=2)

    # README íŒŒì¼ ìƒì„±
    readme_content = f"""# ëª¨ë¸ í•™ìŠµ ì •ë³´

## ê¸°ë³¸ ì •ë³´
- **ëª¨ë¸ëª…**: {training_info['model_name']}
- **ë°ì´í„° ê²½ë¡œ**: {training_info['data_path']}
- **í•™ìŠµ ì‹œì‘ ì‹œê°„**: {training_info['training_start_time']}
- **í•˜ë“œì›¨ì–´**: {training_info['hardware_info']}

## í•™ìŠµ ì„¤ì •
- **ì—í¬í¬ ìˆ˜**: {training_info['training_config']['num_train_epochs']}
- **ë°°ì¹˜ í¬ê¸°**: {training_info['training_config']['per_device_train_batch_size']}
- **í•™ìŠµë¥ **: {training_info['training_config']['learning_rate']}
- **ì‹œí€€ìŠ¤ ê¸¸ì´**: {training_info['tokenizer_config']['encoder_max_len']}/{training_info['tokenizer_config']['decoder_max_len']}

## LoRA ì„¤ì •
- **í™œì„±í™”**: {training_info['lora_config'].get('enabled', False)}
- **QLoRA**: {training_info['lora_config'].get('use_qlora', False)}
- **Rank**: {training_info['lora_config'].get('r', 'N/A')}

## íŒŒì¼ êµ¬ì¡°
- `pytorch_model.bin` ë˜ëŠ” `model.safetensors`: í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜
- `config.json`: ëª¨ë¸ ì„¤ì •
- `tokenizer.json`, `tokenizer_config.json`: í† í¬ë‚˜ì´ì € ì„¤ì •
- `training_args.bin`: í•™ìŠµ ì¸ì
- `trainer_state.json`: í•™ìŠµ ìƒíƒœ
- `logs/`: í…ì„œë³´ë“œ ë¡œê·¸
- `training_info.json`: ìƒì„¸ í•™ìŠµ ì •ë³´
"""

    readme_file = os.path.join(output_dir, 'README.md')
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)

    print(f"ğŸ“„ í•™ìŠµ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {info_file}")
    print(f"ğŸ“„ README íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {readme_file}")


def update_training_completion_info(config, trainer):
    """í•™ìŠµ ì™„ë£Œ í›„ ì •ë³´ ì—…ë°ì´íŠ¸"""
    output_dir = config['general']['output_dir']

    # ê¸°ì¡´ ì •ë³´ ë¡œë“œ
    import json
    info_file = os.path.join(output_dir, 'training_info.json')

    try:
        with open(info_file, 'r', encoding='utf-8') as f:
            training_info = json.load(f)
    except:
        training_info = {}

    # í•™ìŠµ ì™„ë£Œ ì •ë³´ ì¶”ê°€
    training_info.update({
        'training_end_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'training_completed': True,
        'final_global_step': trainer.state.global_step if trainer else 'unknown',
        'best_metric': trainer.state.best_metric if trainer and hasattr(trainer.state, 'best_metric') else 'unknown',
        'total_epochs_completed': trainer.state.epoch if trainer else 'unknown',
    })

    # ì—…ë°ì´íŠ¸ëœ ì •ë³´ ì €ì¥
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(training_info, f, ensure_ascii=False, indent=2)

    print(f"âœ… í•™ìŠµ ì™„ë£Œ ì •ë³´ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤: {info_file}")


def run_training(config):
    """í•™ìŠµ ì‹¤í–‰"""
    print("=" * 80)
    print("í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 80)

    # K-Fold êµì°¨ ê²€ì¦ í™•ì¸
    if config.get('kfold', {}).get('enabled', False):
        return run_kfold_training(config)

    # ì¼ë°˜ í•™ìŠµ
    # í•™ìŠµ ì •ë³´ ì €ì¥
    save_training_info(config)

    # 1. ë°ì´í„° ì²˜ë¦¬
    print("\n1. ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„")
    data_processor = DataProcessor(config)

    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (ë°ì´í„° ì²˜ë¦¬ìš©)
    model_manager = ModelManager(config)
    model, tokenizer = model_manager.load_model_and_tokenizer(
        for_training=True)

    # ë°ì´í„°ì…‹ ì¤€ë¹„
    train_dataset, val_dataset = data_processor.prepare_train_dataset(
        tokenizer)

    # 2. í•™ìŠµ ì‹¤í–‰
    print("\n2. ëª¨ë¸ í•™ìŠµ ë‹¨ê³„")
    training_manager = TrainingManager(config)
    trainer = training_manager.train(train_dataset, val_dataset)

    # í•™ìŠµ ì™„ë£Œ í›„ ì •ë³´ ì—…ë°ì´íŠ¸
    update_training_completion_info(config, trainer)

    return trainer


def run_kfold_training(config):
    """K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì‹¤í–‰"""
    print("=" * 80)
    print("K-FOLD êµì°¨ ê²€ì¦ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 80)

    kfold_config = config.get('kfold', {})
    n_splits = kfold_config.get('n_splits', 5)
    ensemble_method = kfold_config.get('ensemble_method', 'voting')

    print(f"ğŸ”„ K-Fold ì„¤ì •:")
    print(f"   - Fold ìˆ˜: {n_splits}")
    print(f"   - ì•™ìƒë¸” ë°©ë²•: {ensemble_method}")
    print(f"   - ê³„ì¸µí™”: {kfold_config.get('stratified', False)}")

    # K-Fold í•™ìŠµ ì •ë³´ ì €ì¥
    save_kfold_training_info(config)

    # K-Fold ë§¤ë‹ˆì € ìƒì„±
    kfold_manager = KFoldManager(config)

    # ë°ì´í„° ê²½ë¡œ í™•ì¸
    data_path = config['general']['data_path']

    # CSV ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
    json_data_path = prepare_data_for_kfold(data_path)

    try:
        # K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì‹¤í–‰
        fold_results = kfold_manager.run_kfold_training(json_data_path)

        # ì„±ê³µí•œ fold ìˆ˜ í™•ì¸
        successful_folds = [r for r in fold_results if r.get(
            'training_completed', False)]

        print(f"\nğŸ‰ K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì™„ë£Œ!")
        print(f"   - ì„±ê³µí•œ fold: {len(successful_folds)}/{n_splits}")

        if successful_folds:
            # ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰ (ì˜µì…˜)
            if kfold_config.get('use_ensemble_inference', True):
                print(f"\nğŸ¯ ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰ ì¤‘...")
                ensemble_result = kfold_manager.ensemble_inference()
                print(
                    f"   - ì•™ìƒë¸” ì¶”ë¡  ì™„ë£Œ: {len(ensemble_result.get('predictions', []))} ê°œ ì˜ˆì¸¡")

        return fold_results

    except Exception as e:
        print(f"\nâŒ K-Fold í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


def prepare_data_for_kfold(data_path):
    """K-Foldìš© ë°ì´í„° ì¤€ë¹„ (train.csv + dev.csv í•©ì¹˜ê³  ì¦ê°• ë°ì´í„° ì§€ì›)"""
    import pandas as pd
    import json
    import os
    import glob

    print(f"ğŸ“ K-Fold ë°ì´í„° ì¤€ë¹„ ì‹œì‘: {data_path}")

    # ì´ë¯¸ JSON íŒŒì¼ì¸ ê²½ìš°
    if data_path.endswith('.json') or data_path.endswith('.jsonl'):
        print(f"âœ… JSON íŒŒì¼ ì§ì ‘ ì‚¬ìš©: {data_path}")
        return data_path

    # ì¦ê°• ë°ì´í„° í´ë”ì¸ì§€ í™•ì¸ (augmented_ë¡œ ì‹œì‘í•˜ëŠ” í´ë”)
    if os.path.basename(data_path).startswith('augmented_'):
        print(f"ğŸ” ì¦ê°• ë°ì´í„° í´ë” ê°ì§€: {os.path.basename(data_path)}")
        return prepare_augmented_data_for_kfold(data_path)

    # ì¼ë°˜ ë°ì´í„° í´ë” ì²˜ë¦¬
    return prepare_standard_data_for_kfold(data_path)


def prepare_standard_data_for_kfold(data_path):
    """í‘œì¤€ ë°ì´í„° í´ë” ì²˜ë¦¬ (train.csv + dev.csv í•©ì¹˜ê¸°)"""
    import pandas as pd
    import json
    import os

    train_csv = os.path.join(data_path, 'train.csv')
    dev_csv = os.path.join(data_path, 'dev.csv')

    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    if not os.path.exists(train_csv):
        raise FileNotFoundError(f"í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_csv}")

    print(f"ğŸ“Š ë°ì´í„° íŒŒì¼ ë¡œë“œ ì¤‘...")
    print(f"   - Train: {train_csv}")

    # train.csv ë¡œë“œ
    train_df = pd.read_csv(train_csv)
    print(f"   - Train ìƒ˜í”Œ ìˆ˜: {len(train_df)}")

    # dev.csvê°€ ìˆìœ¼ë©´ í•©ì¹˜ê¸°
    if os.path.exists(dev_csv):
        print(f"   - Dev: {dev_csv}")
        dev_df = pd.read_csv(dev_csv)
        print(f"   - Dev ìƒ˜í”Œ ìˆ˜: {len(dev_df)}")

        # trainê³¼ dev í•©ì¹˜ê¸°
        combined_df = pd.concat([train_df, dev_df], ignore_index=True)
        print(f"âœ… Train + Dev ë°ì´í„° í•©ì¹˜ê¸° ì™„ë£Œ: {len(combined_df)} ìƒ˜í”Œ")
    else:
        print(f"âš ï¸ dev.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ train.csvë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        combined_df = train_df

    # JSON í˜•íƒœë¡œ ë³€í™˜
    json_data = []
    for _, row in combined_df.iterrows():
        json_data.append({
            'dialogue': row['dialogue'],
            'summary': row['summary'],
            'fname': row.get('fname', f'combined_{len(json_data)}')
        })

    # JSON íŒŒì¼ë¡œ ì €ì¥
    json_path = os.path.join(data_path, 'kfold_combined_data.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ K-Foldìš© í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {json_path}")
    print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(json_data)}")
    print(f"   - Train ì›ë³¸: {len(train_df)} ìƒ˜í”Œ")
    if os.path.exists(dev_csv):
        print(f"   - Dev ì›ë³¸: {len(dev_df)} ìƒ˜í”Œ")

    return json_path


def prepare_augmented_data_for_kfold(data_path):
    """ì¦ê°• ë°ì´í„° í´ë” ì²˜ë¦¬"""
    import pandas as pd
    import json
    import os
    import glob

    print(f"ğŸ” ì¦ê°• ë°ì´í„° í´ë” ë¶„ì„ ì¤‘: {data_path}")

    # ì¦ê°• ë°ì´í„° í´ë”ì—ì„œ CSV íŒŒì¼ë“¤ ì°¾ê¸°
    csv_files = glob.glob(os.path.join(data_path, '*.csv'))

    if not csv_files:
        raise FileNotFoundError(f"ì¦ê°• ë°ì´í„° í´ë”ì— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_path}")

    print(f"ğŸ“Š ë°œê²¬ëœ CSV íŒŒì¼ë“¤:")
    all_data = []
    total_samples = 0

    for csv_file in sorted(csv_files):
        filename = os.path.basename(csv_file)
        print(f"   - {filename}")

        try:
            df = pd.read_csv(csv_file)
            print(f"     â”” ìƒ˜í”Œ ìˆ˜: {len(df)}")

            # ë°ì´í„° í˜•ì‹ í™•ì¸ ë° ë³€í™˜
            if 'dialogue' in df.columns and 'summary' in df.columns:
                # í‘œì¤€ í˜•ì‹
                for _, row in df.iterrows():
                    all_data.append({
                        'dialogue': str(row['dialogue']),
                        'summary': str(row['summary']),
                        'fname': row.get('fname', f'{filename}_{len(all_data)}'),
                        'source_file': filename
                    })
            elif 'input' in df.columns and 'output' in df.columns:
                # ë‹¤ë¥¸ í˜•ì‹
                for _, row in df.iterrows():
                    all_data.append({
                        'dialogue': str(row['input']),
                        'summary': str(row['output']),
                        'fname': row.get('fname', f'{filename}_{len(all_data)}'),
                        'source_file': filename
                    })
            else:
                print(f"     âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼ í˜•ì‹: {df.columns.tolist()}")
                continue

            total_samples += len(df)

        except Exception as e:
            print(f"     âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue

    if not all_data:
        raise ValueError(f"ì¦ê°• ë°ì´í„° í´ë”ì—ì„œ ìœ íš¨í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")

    # JSON íŒŒì¼ë¡œ ì €ì¥
    json_path = os.path.join(data_path, 'kfold_augmented_data.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… ì¦ê°• ë°ì´í„° í†µí•© ì™„ë£Œ!")
    print(
        f"   - ì´ CSV íŒŒì¼: {len([f for f in csv_files if f.endswith('.csv')])}")
    print(f"   - ì´ ìƒ˜í”Œ ìˆ˜: {len(all_data)}")
    print(f"   - ì €ì¥ ê²½ë¡œ: {json_path}")

    # ë°ì´í„° ì†ŒìŠ¤ë³„ í†µê³„ ì¶œë ¥
    source_stats = {}
    for item in all_data:
        source = item.get('source_file', 'unknown')
        source_stats[source] = source_stats.get(source, 0) + 1

    print(f"ğŸ“ˆ ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬:")
    for source, count in sorted(source_stats.items()):
        print(f"   - {source}: {count} ìƒ˜í”Œ ({count/len(all_data)*100:.1f}%)")

    return json_path


def save_kfold_training_info(config):
    """K-Fold í•™ìŠµ ì •ë³´ ì €ì¥"""
    output_dir = config['general']['output_dir']
    kfold_config = config.get('kfold', {})

    # K-Fold í•™ìŠµ ì •ë³´ ìˆ˜ì§‘
    kfold_info = {
        'training_type': 'kfold_cross_validation',
        'model_name': config['general']['model_name'],
        'data_path': config['general']['data_path'],
        'training_start_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'kfold_config': kfold_config,
        'training_config': config['training'],
        'tokenizer_config': config['tokenizer'],
        'hardware_info': config['general'].get('hardware', 'unknown'),
        'lora_config': config.get('lora', {}),
    }

    # JSON íŒŒì¼ë¡œ ì €ì¥
    import json
    info_file = os.path.join(output_dir, 'kfold_training_info.json')
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(kfold_info, f, ensure_ascii=False, indent=2)

    # K-Fold README íŒŒì¼ ìƒì„±
    readme_content = f"""# K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì •ë³´

## ê¸°ë³¸ ì •ë³´
- **í•™ìŠµ ë°©ì‹**: K-Fold êµì°¨ ê²€ì¦
- **ëª¨ë¸ëª…**: {kfold_info['model_name']}
- **ë°ì´í„° ê²½ë¡œ**: {kfold_info['data_path']}
- **í•™ìŠµ ì‹œì‘ ì‹œê°„**: {kfold_info['training_start_time']}
- **í•˜ë“œì›¨ì–´**: {kfold_info['hardware_info']}

## K-Fold ì„¤ì •
- **Fold ìˆ˜**: {kfold_config.get('n_splits', 5)}
- **ê³„ì¸µí™”**: {kfold_config.get('stratified', False)}
- **ì•™ìƒë¸” ë°©ë²•**: {kfold_config.get('ensemble_method', 'voting')}
- **ëœë¤ ì‹œë“œ**: {kfold_config.get('random_state', 42)}

## í•™ìŠµ ì„¤ì •
- **ì—í¬í¬ ìˆ˜**: {kfold_info['training_config']['num_train_epochs']}
- **ë°°ì¹˜ í¬ê¸°**: {kfold_info['training_config']['per_device_train_batch_size']}
- **í•™ìŠµë¥ **: {kfold_info['training_config']['learning_rate']}
- **ì‹œí€€ìŠ¤ ê¸¸ì´**: {kfold_info['tokenizer_config']['encoder_max_len']}/{kfold_info['tokenizer_config']['decoder_max_len']}

## LoRA ì„¤ì •
- **í™œì„±í™”**: {kfold_info['lora_config'].get('enabled', False)}
- **QLoRA**: {kfold_info['lora_config'].get('use_qlora', False)}
- **Rank**: {kfold_info['lora_config'].get('r', 'N/A')}

## í´ë” êµ¬ì¡°
- `kfold_results/`: K-Fold ê²°ê³¼ í´ë”
  - `fold_1/`, `fold_2/`, ...: ê° foldë³„ ëª¨ë¸
  - `ensemble/`: ì•™ìƒë¸” ê²°ê³¼
  - `kfold_summary.json`: K-Fold ìš”ì•½ ì •ë³´
  - `split_info.json`: ë°ì´í„° ë¶„í•  ì •ë³´
- `kfold_training_info.json`: ìƒì„¸ í•™ìŠµ ì •ë³´
"""

    readme_file = os.path.join(output_dir, 'KFOLD_README.md')
    with open(readme_file, 'w', encoding='utf-8') as f:
        f.write(readme_content)

    print(f"ğŸ“„ K-Fold í•™ìŠµ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {info_file}")
    print(f"ğŸ“„ K-Fold README íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {readme_file}")


def find_latest_model_path(base_output_dir='./model_output/'):
    """ìµœì‹  í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°"""
    if not os.path.exists(base_output_dir):
        return None

    # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ í´ë”ë“¤ ì°¾ê¸°
    model_folders = []
    for folder in os.listdir(base_output_dir):
        folder_path = os.path.join(base_output_dir, folder)
        if os.path.isdir(folder_path):
            # í´ë”ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì‹œë„
            parts = folder.split('_')
            if len(parts) >= 3:  # model_name_YYYYMMDD_HHMMSS í˜•ì‹
                try:
                    timestamp = f"{parts[-2]}_{parts[-1]}"
                    datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
                    model_folders.append((folder_path, timestamp))
                except:
                    continue

    if not model_folders:
        return None

    # íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœì‹  í´ë” ë°˜í™˜
    model_folders.sort(key=lambda x: x[1], reverse=True)
    latest_path = model_folders[0][0]

    print(f"ğŸ” ìµœì‹  ëª¨ë¸ ê²½ë¡œ ê°ì§€: {os.path.basename(latest_path)}")
    return latest_path


def run_inference(config):
    """ì¶”ë¡  ì‹¤í–‰"""
    print("=" * 80)
    print("ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 80)

    # ëª¨ë¸ ê²½ë¡œ ìë™ ê°ì§€ (ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°)
    if config['inference']['ckt_path'] == './model_output/':
        latest_model_path = find_latest_model_path()
        if latest_model_path:
            config['inference']['ckt_path'] = latest_model_path
            print(f"ğŸ“ ìë™ ê°ì§€ëœ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©: {latest_model_path}")
        else:
            print("âš ï¸ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # K-Fold ì•™ìƒë¸” ì¶”ë¡  í™•ì¸
    kfold_results_path = os.path.join(
        config['inference']['ckt_path'], 'kfold_results')
    if os.path.exists(kfold_results_path) and config.get('kfold', {}).get('use_ensemble_inference', False):
        return run_kfold_inference(config)

    # ì¼ë°˜ ì¶”ë¡ 
    # 1. ë°ì´í„° ì²˜ë¦¬
    print("\n1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„")
    data_processor = DataProcessor(config)

    # 2. ëª¨ë¸ ë¡œë“œ
    print("\n2. ëª¨ë¸ ë¡œë“œ ë‹¨ê³„")
    model_manager = ModelManager(config)
    model, tokenizer = model_manager.load_model_and_tokenizer(
        for_training=False)

    # 3. ì¶”ë¡  ì‹¤í–‰ (ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìë™ ì‚¬ìš©)
    print("\n3. ì¶”ë¡  ì‹¤í–‰ ë‹¨ê³„")
    inference_manager = InferenceManager(config)
    results = inference_manager.run_inference(model, tokenizer, data_processor)

    return results


def run_kfold_inference(config):
    """K-Fold ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰"""
    print("=" * 80)
    print("K-FOLD ì•™ìƒë¸” ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("=" * 80)

    # K-Fold ë§¤ë‹ˆì € ìƒì„±
    kfold_manager = KFoldManager(config)

    try:
        # ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰
        ensemble_result = kfold_manager.ensemble_inference()

        print(f"\nğŸ‰ K-Fold ì•™ìƒë¸” ì¶”ë¡  ì™„ë£Œ!")
        print(f"   - ì•™ìƒë¸” ë°©ë²•: {ensemble_result.get('method', 'unknown')}")
        print(f"   - ì‚¬ìš©ëœ ëª¨ë¸ ìˆ˜: {ensemble_result.get('fold_count', 0)}")
        print(f"   - ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜: {len(ensemble_result.get('predictions', []))}")

        return ensemble_result

    except Exception as e:
        print(f"\nâŒ K-Fold ì•™ìƒë¸” ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ì¼ë°˜ ì¶”ë¡ ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤...")

        # ì¼ë°˜ ì¶”ë¡ ìœ¼ë¡œ fallback
        config['kfold']['use_ensemble_inference'] = False
        return run_inference(config)


def run_interactive(config):
    """ëŒ€í™”í˜• ì¶”ë¡  ì‹¤í–‰"""
    print("=" * 80)
    print("ëŒ€í™”í˜• ì¶”ë¡  ëª¨ë“œ")
    print("=" * 80)

    # ëª¨ë¸ ê²½ë¡œ ìë™ íƒì§€ ë˜ëŠ” ì‚¬ìš©ì ì§€ì •
    if config['inference']['ckt_path'] == './model_output/':
        # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì°¾ê¸°
        if os.path.exists("model_output"):
            model_dirs = [
                d
                for d in os.listdir("model_output")
                if os.path.isdir(f"model_output/{d}")
            ]
            if model_dirs:
                latest_dir = sorted(model_dirs)[-1]  # ê°€ì¥ ìµœê·¼ (ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬)
                model_path = f"model_output/{latest_dir}/final"
                print(f"ğŸ” ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì‚¬ìš©: {model_path}")
            else:
                print("âŒ model_output í´ë”ì— ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
        else:
            print("âŒ model_output í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return

    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return

    # ëª¨ë¸ ë¡œë“œ
    model_manager = ModelManager(config)
    model, tokenizer = model_manager.load_model_and_tokenizer(
        for_training=False)

    # ëŒ€í™”í˜• ì¶”ë¡  ì‹œì‘
    interactive = InteractiveInference(config, model, tokenizer)
    interactive.start_interactive_mode()


def main():
    parser = argparse.ArgumentParser(description='ëŒ€í™” ìš”ì•½ ëª¨ë¸ íŒŒì´í”„ë¼ì¸')

    # ì‹¤í–‰ ëª¨ë“œ
    parser.add_argument('--mode', choices=['train', 'inference', 'interactive', 'config'],
                        default='train', help='ì‹¤í–‰ ëª¨ë“œ')

    # ì„¤ì • ê´€ë ¨
    parser.add_argument('--config', default='config.yaml', help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--create-config',
                        action='store_true', help='ìƒˆ ì„¤ì • íŒŒì¼ ìƒì„±')
    parser.add_argument('--optimize-rtx3060',
                        action='store_true', help='RTX 3060 ê¸°ë³¸ ìµœì í™” ì„¤ì •')
    parser.add_argument('--high-quality-rtx3060',
                        action='store_true', help='RTX 3060 ê³ í’ˆì§ˆ ì„¤ì • (Final Score ìµœëŒ€í™”)')
    parser.add_argument('--balanced-rtx3060',
                        action='store_true', help='RTX 3060 ê· í˜• ì„¤ì • (ì†ë„ì™€ í’ˆì§ˆ ê· í˜•)')

    # RTX 3090 Baseline ì„¤ì • (baseline.ipynb ê¸°ë°˜)
    parser.add_argument('--rtx3090-baseline',
                        action='store_true', help='RTX 3090 Baseline ì„¤ì • (baseline.ipynb ê¸°ë°˜)')
    parser.add_argument('--rtx3090-baseline-kfold',
                        action='store_true', help='RTX 3090 Baseline + K-Fold ì„¤ì •')
    parser.add_argument('--rtx3090-baseline-fast',
                        action='store_true', help='RTX 3090 ë¹ ë¥¸ Baseline ì„¤ì • (ì‹¤í—˜ìš©)')

    # K-Fold êµì°¨ ê²€ì¦ ì„¤ì •
    parser.add_argument('--kfold-rtx3060',
                        action='store_true', help='RTX 3060ìš© K-Fold êµì°¨ ê²€ì¦ ì„¤ì •')
    parser.add_argument('--kfold-high-performance',
                        action='store_true', help='ê³ ì„±ëŠ¥ GPUìš© K-Fold êµì°¨ ê²€ì¦ ì„¤ì •')
    parser.add_argument('--fast-kfold-rtx3060',
                        action='store_true', help='RTX 3060ìš© ë¹ ë¥¸ K-Fold ì„¤ì • (ì‹¤í—˜ìš©)')
    parser.add_argument('--kfold-splits', type=int, default=5,
                        help='K-Fold ë¶„í•  ìˆ˜ (ê¸°ë³¸ê°’: 5)')
    parser.add_argument('--ensemble-method', choices=['voting', 'weighted', 'best'],
                        default='voting', help='ì•™ìƒë¸” ë°©ë²• (ê¸°ë³¸ê°’: voting)')

    # ëª¨ë¸ ë° ë°ì´í„° ì„¤ì •
    parser.add_argument('--model-name', help='ì‚¬ìš©í•  ëª¨ë¸ëª…')
    parser.add_argument(
        '--data-path', help='ë°ì´í„° ê²½ë¡œ (ì¼ë°˜ í´ë” ë˜ëŠ” ì¦ê°• ë°ì´í„° í´ë” - augmented_ë¡œ ì‹œì‘í•˜ë©´ ìë™ ê°ì§€)')
    parser.add_argument('--output-dir', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')

    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    parser.add_argument('--epochs', type=int, help='í•™ìŠµ ì—í­ ìˆ˜')
    parser.add_argument('--batch-size', type=int, help='ë°°ì¹˜ í¬ê¸°')
    parser.add_argument('--learning-rate', type=float, help='í•™ìŠµë¥ ')

    args = parser.parse_args()

    try:
        # ì„¤ì • ì´ˆê¸°í™”
        config = setup_config(args)

        # ëª¨ë“œë³„ ì‹¤í–‰
        if args.mode == 'config':
            print("ì„¤ì • íŒŒì¼ì´ ìƒì„±/ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

        elif args.mode == 'train':
            trainer = run_training(config)
            print("í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ“ ëª¨ë¸ì´ ì €ì¥ëœ ìœ„ì¹˜: {config['general']['output_dir']}")

        elif args.mode == 'inference':
            results = run_inference(config)
            print(f"ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê²°ê³¼: {len(results)} ê°œ")

        elif args.mode == 'interactive':
            run_interactive(config)

    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
