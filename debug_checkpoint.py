import json
import os
from transformers import AutoTokenizer

def debug_checkpoint(path: str):
    """
    ì €ì¥ëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ì˜ ì„¤ì •ê³¼ í† í¬ë‚˜ì´ì €ì˜ ìƒíƒœë¥¼ ë¹„êµí•˜ì—¬
    'size mismatch' ì˜¤ë¥˜ì˜ ì›ì¸ì„ ì§„ë‹¨í•©ë‹ˆë‹¤.
    """
    print(f"--- ğŸ•µï¸â€â™‚ï¸ Debugging Checkpoint at: {path} ---")

    # 1. ëª¨ë¸ ì„¤ì • íŒŒì¼(config.json) í™•ì¸
    config_file_path = os.path.join(path, "config.json")
    vocab_size_in_config = "N/A"
    if os.path.exists(config_file_path):
        with open(config_file_path, 'r', encoding='utf-8') as f:
            model_config = json.load(f)
        vocab_size_in_config = model_config.get("vocab_size")
        print(f"\n[1] Found 'config.json'.")
        print(f"    - 'vocab_size' in config.json: {vocab_size_in_config}")
    else:
        print("\n[1] 'config.json' not found in the checkpoint directory.")

    # 2. í† í¬ë‚˜ì´ì €(tokenizer) í™•ì¸
    vocab_size_in_tokenizer = "N/A"
    try:
        tokenizer = AutoTokenizer.from_pretrained(path)
        vocab_size_in_tokenizer = len(tokenizer)
        print(f"\n[2] Loaded tokenizer from checkpoint.")
        print(f"    - vocab_size from len(tokenizer): {vocab_size_in_tokenizer}")
    except Exception as e:
        print(f"\n[2] Failed to load tokenizer from checkpoint. Error: {e}")
        
    # 3. ìµœì¢… ì§„ë‹¨
    print("\n--- ğŸ©º Final Diagnosis ---")
    if vocab_size_in_config == vocab_size_in_tokenizer:
        print("âœ… The vocab sizes seem to match. The problem might be more subtle.")
    else:
        print(f"âŒ MISMATCH FOUND! The model config says {vocab_size_in_config}, but the tokenizer has {vocab_size_in_tokenizer} tokens.")
        print("This confirms the root cause of the 'size mismatch' error.")
    print("-" * 40)


if __name__ == "__main__":
    # â—ï¸ì´ ê²½ë¡œë¥¼ ì‹¤ì œ best_modelì´ ì €ì¥ëœ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
    checkpoint_path = "results/best_model" 
    
    if not os.path.isdir(checkpoint_path):
        print(f"Error: Directory not found at '{checkpoint_path}'. Please make sure the path is correct.")
    else:
        debug_checkpoint(checkpoint_path)