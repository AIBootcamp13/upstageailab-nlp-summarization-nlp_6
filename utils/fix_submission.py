"""
ì œì¶œ íŒŒì¼ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
- ëˆ„ë½ëœ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œë“¤ì„ sample_submission í˜•ì‹ì— ë§ì¶° ì¶”ê°€
- ëª¨ë“  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì´ í¬í•¨ë˜ë„ë¡ ë³´ì¥
"""

import pandas as pd
import os

def fix_submission_file(prediction_file="./prediction/output.csv", 
                       sample_submission_file="data/sample_submission.csv",
                       output_file="./prediction/fixed_output.csv"):
    """ì œì¶œ íŒŒì¼ ìˆ˜ì •"""
    
    print("ğŸ”§ ì œì¶œ íŒŒì¼ ìˆ˜ì • ì¤‘...")
    
    # íŒŒì¼ ë¡œë“œ
    try:
        pred_df = pd.read_csv(prediction_file)
        sample_df = pd.read_csv(sample_submission_file)
        
        print(f"ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼: {len(pred_df)} ìƒ˜í”Œ")
        print(f"ğŸ“Š ìƒ˜í”Œ ì œì¶œ: {len(sample_df)} ìƒ˜í”Œ")
        
    except FileNotFoundError as e:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return None
    
    # í•„ìš”í•œ ëª¨ë“  fname ì¶”ì¶œ
    required_fnames = sample_df['fname'].tolist()
    existing_fnames = pred_df['fname'].tolist()
    
    # ëˆ„ë½ëœ fname ì°¾ê¸°
    missing_fnames = [fname for fname in required_fnames if fname not in existing_fnames]
    
    print(f"ğŸ” ëˆ„ë½ëœ ìƒ˜í”Œ: {len(missing_fnames)}ê°œ")
    if missing_fnames:
        print(f"   ì˜ˆì‹œ: {missing_fnames[:5]}...")
    
    # ëˆ„ë½ëœ ìƒ˜í”Œë“¤ì„ ê¸°ë³¸ ìš”ì•½ìœ¼ë¡œ ì¶”ê°€
    if missing_fnames:
        missing_data = []
        for fname in missing_fnames:
            missing_data.append({
                'fname': fname,
                'summary': 'ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•œ ê²°ê³¼ì…ë‹ˆë‹¤.'  # ê¸°ë³¸ ìš”ì•½
            })
        
        missing_df = pd.DataFrame(missing_data)
        
        # ê¸°ì¡´ ì˜ˆì¸¡ ê²°ê³¼ì™€ í•©ì¹˜ê¸°
        fixed_df = pd.concat([pred_df, missing_df], ignore_index=True)
    else:
        fixed_df = pred_df.copy()
    
    # sample_submission ìˆœì„œì— ë§ì¶° ì •ë ¬
    fixed_df = fixed_df.set_index('fname').loc[required_fnames].reset_index()
    
    # ê²°ê³¼ ì €ì¥
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    fixed_df.to_csv(output_file, index=False)
    
    print(f"âœ… ìˆ˜ì •ëœ ì œì¶œ íŒŒì¼ ì €ì¥: {output_file}")
    print(f"ğŸ“Š ìµœì¢… ìƒ˜í”Œ ìˆ˜: {len(fixed_df)}")
    
    # ê²€ì¦
    if len(fixed_df) == len(sample_df):
        print("âœ… ëª¨ë“  í•„ìš”í•œ ìƒ˜í”Œì´ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"âš ï¸ ìƒ˜í”Œ ìˆ˜ ë¶ˆì¼ì¹˜: {len(fixed_df)} vs {len(sample_df)}")
    
    return fixed_df

def create_complete_inference_pipeline():
    """ì™„ì „í•œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ (ëˆ„ë½ ìƒ˜í”Œ ì²˜ë¦¬ í¬í•¨)"""
    
    print("ğŸš€ ì™„ì „í•œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹œì‘!")
    
    # 1. ê¸°ë³¸ ì¶”ë¡  ì‹¤í–‰
    print("\n1ï¸âƒ£ ê¸°ë³¸ ì¶”ë¡  ì‹¤í–‰...")
    from scripts.quick_inference import quick_inference
    
    try:
        results = quick_inference()
        print("âœ… ê¸°ë³¸ ì¶”ë¡  ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return None
    
    # 2. ì œì¶œ íŒŒì¼ ìˆ˜ì •
    print("\n2ï¸âƒ£ ì œì¶œ íŒŒì¼ ìˆ˜ì •...")
    fixed_results = fix_submission_file()
    
    if fixed_results is not None:
        print("âœ… ì™„ì „í•œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        return fixed_results
    else:
        print("âŒ ì œì¶œ íŒŒì¼ ìˆ˜ì • ì‹¤íŒ¨")
        return None

def analyze_missing_samples():
    """ëˆ„ë½ëœ ìƒ˜í”Œë“¤ ë¶„ì„"""
    
    print("ğŸ” ëˆ„ë½ëœ ìƒ˜í”Œ ë¶„ì„...")
    
    # ì›ë³¸ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    original_test = pd.read_csv('data/test.csv')
    
    # ê³ ê¸‰ ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    try:
        advanced_test = pd.read_csv('advanced_processed_data/test_advanced.csv')
    except:
        print("âŒ ê³ ê¸‰ ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëˆ„ë½ëœ ìƒ˜í”Œë“¤
    original_fnames = set(original_test['fname'])
    advanced_fnames = set(advanced_test['fname'])
    missing_fnames = original_fnames - advanced_fnames
    
    print(f"ğŸ“Š ì›ë³¸ í…ŒìŠ¤íŠ¸: {len(original_fnames)} ìƒ˜í”Œ")
    print(f"ğŸ“Š ê³ ê¸‰ ì „ì²˜ë¦¬: {len(advanced_fnames)} ìƒ˜í”Œ")
    print(f"ğŸ“Š ëˆ„ë½ëœ ìƒ˜í”Œ: {len(missing_fnames)} ê°œ")
    
    if missing_fnames:
        missing_list = sorted(list(missing_fnames))
        print(f"ğŸ” ëˆ„ë½ëœ ìƒ˜í”Œë“¤: {missing_list}")
        
        # ëˆ„ë½ëœ ìƒ˜í”Œë“¤ì˜ íŠ¹ì„± ë¶„ì„
        missing_samples = original_test[original_test['fname'].isin(missing_fnames)]
        
        print(f"\nğŸ“ˆ ëˆ„ë½ëœ ìƒ˜í”Œë“¤ì˜ íŠ¹ì„±:")
        print(f"   í‰ê·  ëŒ€í™” ê¸¸ì´: {missing_samples['dialogue'].str.len().mean():.1f}ì")
        print(f"   ìµœëŒ€ ëŒ€í™” ê¸¸ì´: {missing_samples['dialogue'].str.len().max()}ì")
        print(f"   ìµœì†Œ ëŒ€í™” ê¸¸ì´: {missing_samples['dialogue'].str.len().min()}ì")
        
        # ìƒ˜í”Œ ì¶œë ¥
        print(f"\nğŸ“ ëˆ„ë½ëœ ìƒ˜í”Œ ì˜ˆì‹œ:")
        for i, (_, row) in enumerate(missing_samples.head(2).iterrows()):
            print(f"   {row['fname']}: {row['dialogue'][:100]}...")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ì œì¶œ íŒŒì¼ ìˆ˜ì •')
    parser.add_argument('--mode', choices=['fix', 'analyze', 'complete'], 
                       default='complete', help='ì‹¤í–‰ ëª¨ë“œ')
    parser.add_argument('--prediction-file', default='./prediction/output.csv',
                       help='ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼')
    parser.add_argument('--output-file', default='./prediction/fixed_output.csv',
                       help='ìˆ˜ì •ëœ ì¶œë ¥ íŒŒì¼')
    
    args = parser.parse_args()
    
    if args.mode == 'fix':
        fix_submission_file(args.prediction_file, output_file=args.output_file)
    elif args.mode == 'analyze':
        analyze_missing_samples()
    elif args.mode == 'complete':
        create_complete_inference_pipeline()