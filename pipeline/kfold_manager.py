"""
K-Fold êµì°¨ ê²€ì¦ ê´€ë¦¬ì
ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ K-Fold í•™ìŠµ ë° ì•™ìƒë¸” ì¶”ë¡ 
"""

import os
import json
import numpy as np
import pandas as pd
from datetime import datetime
from sklearn.model_selection import KFold, StratifiedKFold
from typing import List, Dict, Any, Tuple
import logging
from pathlib import Path

from .model_manager import TrainingManager
from .model_manager import ModelManager
from .data_processor import DataProcessor
from .inference_manager import InferenceManager
from utils.unified_metrics import batch_rouge_scores
from utils.memory_monitor import MemoryMonitor, safe_fold_training_wrapper

logger = logging.getLogger(__name__)


class KFoldManager:
    """K-Fold êµì°¨ ê²€ì¦ ê´€ë¦¬ì"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.kfold_config = config.get('kfold', {})
        self.n_splits = self.kfold_config.get('n_splits', 5)
        self.stratified = self.kfold_config.get('stratified', False)
        self.random_state = self.kfold_config.get('random_state', 42)
        self.ensemble_method = self.kfold_config.get(
            'ensemble_method', 'voting')  # voting, weighted, best

        # K-Fold ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.kfold_base_dir = os.path.join(
            config['general']['output_dir'], 'kfold_results')
        os.makedirs(self.kfold_base_dir, exist_ok=True)

        # ê° foldë³„ ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.fold_dirs = []
        for i in range(self.n_splits):
            fold_dir = os.path.join(self.kfold_base_dir, f'fold_{i+1}')
            os.makedirs(fold_dir, exist_ok=True)
            self.fold_dirs.append(fold_dir)

        # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        self.ensemble_dir = os.path.join(self.kfold_base_dir, 'ensemble')
        os.makedirs(self.ensemble_dir, exist_ok=True)

        logger.info(
            f"K-Fold ì„¤ì •: {self.n_splits}ê°œ fold, ë°©ë²•: {'Stratified' if self.stratified else 'Standard'}")

    def create_kfold_splits(self, data_path: str) -> List[Tuple[np.ndarray, np.ndarray]]:
        """K-Fold ë°ì´í„° ë¶„í•  ìƒì„±"""
        logger.info(f"K-Fold ë°ì´í„° ë¶„í•  ìƒì„± ì¤‘... (n_splits={self.n_splits})")

        # ë°ì´í„° ë¡œë“œ
        if data_path.endswith('.json'):
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        elif data_path.endswith('.jsonl'):
            data = []
            with open(data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    data.append(json.loads(line.strip()))
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹: {data_path}")

        # ì¸ë±ìŠ¤ ë°°ì—´ ìƒì„±
        indices = np.arange(len(data))

        # K-Fold ë¶„í• ê¸° ìƒì„±
        if self.stratified:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ê³„ì¸µí™”
            text_lengths = []
            for item in data:
                # ë‹¤ì–‘í•œ í‚¤ í˜•íƒœ ì§€ì›
                text = item.get('dialogue', item.get('input', ''))
                text_lengths.append(len(str(text)))

            # ê¸¸ì´ë¥¼ 5ê°œ êµ¬ê°„ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ê³„ì¸µí™”
            try:
                length_bins = pd.qcut(
                    text_lengths, q=5, labels=False, duplicates='drop')
            except ValueError as e:
                # ì¤‘ë³µê°’ì´ ë§ì•„ì„œ ê³„ì¸µí™”ê°€ ì–´ë ¤ìš´ ê²½ìš° 3ê°œ êµ¬ê°„ìœ¼ë¡œ ì‹œë„
                logger.warning(f"5ê°œ êµ¬ê°„ ê³„ì¸µí™” ì‹¤íŒ¨, 3ê°œ êµ¬ê°„ìœ¼ë¡œ ì‹œë„: {e}")
                try:
                    length_bins = pd.qcut(
                        text_lengths, q=3, labels=False, duplicates='drop')
                except ValueError:
                    # ê³„ì¸µí™”ê°€ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì¼ë°˜ K-Fold ì‚¬ìš©
                    logger.warning("ê³„ì¸µí™” ë¶ˆê°€ëŠ¥, ì¼ë°˜ K-Fold ì‚¬ìš©")
                    self.stratified = False
                    length_bins = None

            if self.stratified and length_bins is not None:
                kfold = StratifiedKFold(
                    n_splits=self.n_splits, shuffle=True, random_state=self.random_state)
                splits = list(kfold.split(indices, length_bins))
            else:
                kfold = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)
                splits = list(kfold.split(indices))

        # ë¶„í•  ì •ë³´ ì €ì¥
        split_info = {
            'n_splits': self.n_splits,
            'stratified': self.stratified,
            'random_state': self.random_state,
            'total_samples': len(data),
            'splits': []
        }

        for i, (train_idx, val_idx) in enumerate(splits):
            split_info['splits'].append({
                'fold': i + 1,
                'train_size': len(train_idx),
                'val_size': len(val_idx),
                'train_indices': train_idx.tolist(),
                'val_indices': val_idx.tolist()
            })

        # ë¶„í•  ì •ë³´ ì €ì¥
        split_info_path = os.path.join(self.kfold_base_dir, 'split_info.json')
        with open(split_info_path, 'w', encoding='utf-8') as f:
            json.dump(split_info, f, ensure_ascii=False, indent=2)

        logger.info(f"K-Fold ë¶„í•  ì™„ë£Œ: {len(splits)}ê°œ fold")
        logger.info(f"ë¶„í•  ì •ë³´ ì €ì¥: {split_info_path}")

        return splits

    def create_fold_datasets(self, data_path: str, train_indices: np.ndarray, val_indices: np.ndarray, fold_num: int):
        """íŠ¹ì • foldì˜ í•™ìŠµ/ê²€ì¦ ë°ì´í„°ì…‹ ìƒì„±"""
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        if data_path.endswith('.json'):
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        elif data_path.endswith('.jsonl'):
            data = []
            with open(data_path, 'r', encoding='utf-8') as f:
                for line in f:
                    data.append(json.loads(line.strip()))

        # ì¸ë±ìŠ¤ì— ë”°ë¼ ë°ì´í„° ë¶„í• 
        train_data = [data[i] for i in train_indices]
        val_data = [data[i] for i in val_indices]

        # foldë³„ ë°ì´í„° ì €ì¥
        fold_dir = self.fold_dirs[fold_num - 1]

        train_path = os.path.join(fold_dir, 'train_data.json')
        val_path = os.path.join(fold_dir, 'val_data.json')

        with open(train_path, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)

        with open(val_path, 'w', encoding='utf-8') as f:
            json.dump(val_data, f, ensure_ascii=False, indent=2)

        logger.info(
            f"Fold {fold_num} ë°ì´í„° ì €ì¥: train={len(train_data)}, val={len(val_data)}")

        return train_path, val_path

    @safe_fold_training_wrapper
    def train_single_fold(self, fold_num: int, train_path: str, val_path: str) -> Dict[str, Any]:
        """ë‹¨ì¼ fold í•™ìŠµ"""
        logger.info(f"=" * 60)
        logger.info(f"Fold {fold_num}/{self.n_splits} í•™ìŠµ ì‹œì‘")
        logger.info(f"=" * 60)

        # foldë³„ ì„¤ì • ë³µì‚¬ ë° ìˆ˜ì •
        fold_config = self.config.copy()
        fold_config['general']['data_path'] = os.path.dirname(train_path)
        fold_config['general']['output_dir'] = self.fold_dirs[fold_num - 1]
        fold_config['training']['output_dir'] = self.fold_dirs[fold_num - 1]
        fold_config['training']['logging_dir'] = os.path.join(
            self.fold_dirs[fold_num - 1], 'logs')

        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(fold_config['training']['logging_dir'], exist_ok=True)

        try:
            # ë°ì´í„° ì²˜ë¦¬
            data_processor = DataProcessor(fold_config)

            # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
            model_manager = ModelManager(fold_config)
            model, tokenizer = model_manager.load_model_and_tokenizer(
                for_training=True)

            # foldë³„ ë°ì´í„°ì…‹ ì¤€ë¹„ (ì§ì ‘ ê²½ë¡œ ì§€ì •)
            train_dataset, val_dataset = data_processor.prepare_fold_dataset(
                tokenizer, train_path, val_path
            )

            # í•™ìŠµ ì‹¤í–‰
            training_manager = TrainingManager(fold_config)
            trainer = training_manager.train(train_dataset, val_dataset)

            # í•™ìŠµ ê²°ê³¼ ìˆ˜ì§‘
            fold_result = {
                'fold_num': fold_num,
                'train_samples': len(train_dataset),
                'val_samples': len(val_dataset),
                'final_step': trainer.state.global_step,
                'best_metric': getattr(trainer.state, 'best_metric', None),
                'training_completed': True,
                'model_path': self.fold_dirs[fold_num - 1]
            }

            # fold ê²°ê³¼ ì €ì¥
            fold_result_path = os.path.join(
                self.fold_dirs[fold_num - 1], 'fold_result.json')
            with open(fold_result_path, 'w', encoding='utf-8') as f:
                json.dump(fold_result, f, ensure_ascii=False, indent=2)

            # ë©”ëª¨ë¦¬ ì •ë¦¬ (ì¤‘ìš”!)
            logger.info(f"Fold {fold_num} ë©”ëª¨ë¦¬ ì •ë¦¬ ì¤‘...")

            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            import torch
            import gc

            # ëª¨ë¸ê³¼ ë°ì´í„°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚­ì œ
            del model
            del tokenizer
            del trainer
            del train_dataset
            del val_dataset
            del training_manager
            del data_processor

            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
            gc.collect()

            # GPU ë©”ëª¨ë¦¬ ìºì‹œ ì •ë¦¬
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

                # GPU ë©”ëª¨ë¦¬ ìƒíƒœ ì¶œë ¥
                allocated = torch.cuda.memory_allocated() / 1024**3
                cached = torch.cuda.memory_reserved() / 1024**3
                logger.info(f"GPU ë©”ëª¨ë¦¬ ì •ë¦¬ í›„ - í• ë‹¹: {allocated:.2f}GB, ìºì‹œ: {cached:.2f}GB")

            # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë¦¬ë¥¼ ìœ„í•œ ì ì‹œ ëŒ€ê¸°
            import time
            time.sleep(2)

            logger.info(f"Fold {fold_num} ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ")

            logger.info(f"Fold {fold_num} í•™ìŠµ ì™„ë£Œ!")
            logger.info(f"ìµœì¢… ìŠ¤í…: {fold_result['final_step']}")
            if fold_result['best_metric']:
                logger.info(f"ìµœê³  ë©”íŠ¸ë¦­: {fold_result['best_metric']:.4f}")

            return fold_result

        except Exception as e:
            logger.error(f"Fold {fold_num} í•™ìŠµ ì‹¤íŒ¨: {e}")
            fold_result = {
                'fold_num': fold_num,
                'training_completed': False,
                'error': str(e)
            }
            return fold_result

    def run_kfold_training(self, data_path: str) -> List[Dict[str, Any]]:
        """K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì‹¤í–‰"""
        logger.info(f"ğŸ”„ K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì‹œì‘ ({self.n_splits} folds)")

        # K-Fold ë¶„í•  ìƒì„±
        splits = self.create_kfold_splits(data_path)

        # ê° foldë³„ í•™ìŠµ ì‹¤í–‰
        fold_results = []

        memory_monitor = MemoryMonitor()

        for i, (train_indices, val_indices) in enumerate(splits):
            fold_num = i + 1

            logger.info(f"ğŸ”„ Fold {fold_num}/{self.n_splits} ì¤€ë¹„ ì¤‘...")

            # ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
            memory_monitor.print_memory_status(f"Fold {fold_num} ì‹œì‘ ì „")

            # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ëŒ€ê¸°
            if not memory_monitor.check_memory_safety(min_gpu_gb=1.5):
                logger.warning(f"Fold {fold_num} ì‹œì‘ ì „ ë©”ëª¨ë¦¬ ë¶€ì¡±, ì •ë¦¬ ë° ëŒ€ê¸°...")
                memory_monitor.cleanup_memory(aggressive=True)
                memory_monitor.wait_for_memory_recovery(max_wait_seconds=60)

            try:
                # foldë³„ ë°ì´í„°ì…‹ ìƒì„±
                train_path, val_path = self.create_fold_datasets(
                    data_path, train_indices, val_indices, fold_num
                )

                # fold í•™ìŠµ ì‹¤í–‰
                fold_result = self.train_single_fold(
                    fold_num, train_path, val_path)
                fold_results.append(fold_result)

                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                self.save_kfold_summary(fold_results, partial=True)

                # fold ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ëŒ€ê¸°
                logger.info(f"Fold {fold_num} ì™„ë£Œ, ë‹¤ìŒ fold ì¤€ë¹„ ì¤‘...")
                memory_monitor.cleanup_memory(aggressive=True)

                # fold ê°„ ì ì‹œ ëŒ€ê¸° (ì‹œìŠ¤í…œ ì•ˆì •í™”)
                import time
                time.sleep(5)

            except Exception as e:
                logger.error(f"Fold {fold_num} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ë©”ëª¨ë¦¬ ì •ë¦¬
                memory_monitor.cleanup_memory(aggressive=True)

                # ì˜¤ë¥˜ ì •ë³´ë¥¼ ê²°ê³¼ì— ì¶”ê°€
                fold_result = {
                    'fold_num': fold_num,
                    'training_completed': False,
                    'error': str(e),
                    'error_type': type(e).__name__
                }
                fold_results.append(fold_result)

                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                self.save_kfold_summary(fold_results, partial=True)

                # ì‹¬ê°í•œ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ì¸ ê²½ìš° ì¤‘ë‹¨
                if 'memory' in str(e).lower() or 'cuda' in str(e).lower():
                    logger.error(f"ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜¤ë¥˜ë¡œ K-Fold í•™ìŠµ ì¤‘ë‹¨: {e}")
                    break

        # ìµœì¢… ê²°ê³¼ ì €ì¥
        self.save_kfold_summary(fold_results, partial=False)

        logger.info(f"ğŸ‰ K-Fold êµì°¨ ê²€ì¦ í•™ìŠµ ì™„ë£Œ!")
        return fold_results

    def save_kfold_summary(self, fold_results: List[Dict[str, Any]], partial: bool = False):
        """K-Fold ê²°ê³¼ ìš”ì•½ ì €ì¥"""
        completed_folds = [r for r in fold_results if r.get(
            'training_completed', False)]
        failed_folds = [r for r in fold_results if not r.get(
            'training_completed', False)]

        summary = {
            'kfold_config': self.kfold_config,
            'total_folds': self.n_splits,
            'completed_folds': len(completed_folds),
            'failed_folds': len(failed_folds),
            'completion_rate': len(completed_folds) / self.n_splits * 100,
            'fold_results': fold_results,
            'summary_created': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'is_partial': partial
        }

        # ì„±ê³µí•œ foldë“¤ì˜ ë©”íŠ¸ë¦­ í†µê³„
        if completed_folds:
            best_metrics = [r['best_metric']
                            for r in completed_folds if r.get('best_metric')]
            if best_metrics:
                summary['metric_stats'] = {
                    'mean': np.mean(best_metrics),
                    'std': np.std(best_metrics),
                    'min': np.min(best_metrics),
                    'max': np.max(best_metrics),
                    'best_fold': completed_folds[np.argmax(best_metrics)]['fold_num']
                }

        # ìš”ì•½ ì €ì¥
        summary_path = os.path.join(self.kfold_base_dir, 'kfold_summary.json')
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        # ì§„í–‰ ìƒí™© ì¶œë ¥
        status = "ì§„í–‰ ì¤‘" if partial else "ì™„ë£Œ"
        logger.info(
            f"ğŸ“Š K-Fold ìš”ì•½ ({status}): {len(completed_folds)}/{self.n_splits} ì™„ë£Œ")
        if completed_folds and 'metric_stats' in summary:
            stats = summary['metric_stats']
            logger.info(f"   í‰ê·  ë©”íŠ¸ë¦­: {stats['mean']:.4f} Â± {stats['std']:.4f}")
            logger.info(
                f"   ìµœê³  ì„±ëŠ¥: Fold {stats['best_fold']} ({stats['max']:.4f})")

    def ensemble_inference(self, test_data_path: str = None) -> Dict[str, Any]:
        """ì•™ìƒë¸” ì¶”ë¡  ì‹¤í–‰"""
        logger.info(f"ğŸ¯ ì•™ìƒë¸” ì¶”ë¡  ì‹œì‘ (ë°©ë²•: {self.ensemble_method})")

        # ì™„ë£Œëœ fold ëª¨ë¸ë“¤ ì°¾ê¸°
        completed_folds = []
        for i in range(self.n_splits):
            fold_dir = self.fold_dirs[i]
            fold_result_path = os.path.join(fold_dir, 'fold_result.json')

            if os.path.exists(fold_result_path):
                with open(fold_result_path, 'r', encoding='utf-8') as f:
                    fold_result = json.load(f)
                    if fold_result.get('training_completed', False):
                        completed_folds.append((i + 1, fold_dir, fold_result))

        if not completed_folds:
            raise ValueError("ì™„ë£Œëœ fold ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

        logger.info(f"ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë¸: {len(completed_folds)}ê°œ")

        # ê° fold ëª¨ë¸ë¡œ ì¶”ë¡  ì‹¤í–‰
        fold_predictions = []

        for fold_num, fold_dir, fold_result in completed_folds:
            logger.info(f"Fold {fold_num} ëª¨ë¸ë¡œ ì¶”ë¡  ì¤‘...")

            try:
                # foldë³„ ì„¤ì • ìƒì„±
                fold_config = self.config.copy()
                fold_config['inference']['ckt_path'] = fold_dir

                # ì¶”ë¡  ì‹¤í–‰
                inference_manager = InferenceManager(fold_config)
                data_processor = DataProcessor(fold_config)

                # ëª¨ë¸ ë¡œë“œ
                model_manager = ModelManager(fold_config)
                model, tokenizer = model_manager.load_model_and_tokenizer(
                    for_training=False)

                # ì¶”ë¡  ì‹¤í–‰
                predictions = inference_manager.run_inference(
                    model, tokenizer, data_processor)

                fold_predictions.append({
                    'fold_num': fold_num,
                    'predictions': predictions,
                    'best_metric': fold_result.get('best_metric', 0.0)
                })

                logger.info(f"Fold {fold_num} ì¶”ë¡  ì™„ë£Œ: {len(predictions)} ê°œ ì˜ˆì¸¡")

            except Exception as e:
                logger.error(f"Fold {fold_num} ì¶”ë¡  ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ foldëŠ” ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
                continue

        # ì•™ìƒë¸” ê²°ê³¼ ìƒì„±
        ensemble_result = self.combine_predictions(fold_predictions)

        # ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ (DataFrameì„ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜)
        serializable_result = self._make_json_serializable(ensemble_result)

        ensemble_result_path = os.path.join(
            self.ensemble_dir, 'ensemble_predictions.json')
        with open(ensemble_result_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)

        # DataFrameì¸ ê²½ìš° CSVë¡œë„ ì €ì¥
        if 'predictions' in ensemble_result:
            predictions = ensemble_result['predictions']
            if hasattr(predictions, 'to_csv'):  # DataFrameì¸ ê²½ìš°
                csv_path = os.path.join(self.ensemble_dir, 'ensemble_predictions.csv')
                predictions.to_csv(csv_path, index=False, encoding='utf-8')
                logger.info(f"ğŸ“„ ì•™ìƒë¸” ê²°ê³¼ CSV ì €ì¥: {csv_path}")

        logger.info(f"ğŸ‰ ì•™ìƒë¸” ì¶”ë¡  ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {ensemble_result_path}")
        return ensemble_result

    def _make_json_serializable(self, obj):
        """ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
        import pandas as pd

        if isinstance(obj, dict):
            result = {}
            for key, value in obj.items():
                if isinstance(value, pd.DataFrame):
                    # DataFrameì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    result[key] = {
                        'type': 'DataFrame',
                        'data': value.to_dict('records'),
                        'columns': value.columns.tolist(),
                        'shape': value.shape
                    }
                elif isinstance(value, (list, dict)):
                    result[key] = self._make_json_serializable(value)
                else:
                    result[key] = value
            return result
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, pd.DataFrame):
            return {
                'type': 'DataFrame',
                'data': obj.to_dict('records'),
                'columns': obj.columns.tolist(),
                'shape': obj.shape
            }
        else:
            return obj

    def combine_predictions(self, fold_predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """foldë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì•™ìƒë¸”ë¡œ ê²°í•©"""
        if self.ensemble_method == 'voting':
            return self._voting_ensemble(fold_predictions)
        elif self.ensemble_method == 'weighted':
            return self._weighted_ensemble(fold_predictions)
        elif self.ensemble_method == 'best':
            return self._best_model_ensemble(fold_predictions)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì•™ìƒë¸” ë°©ë²•: {self.ensemble_method}")

    def _voting_ensemble(self, fold_predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸” (ë‹¨ìˆœ í‰ê· )"""
        logger.info("íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸” ìˆ˜í–‰ ì¤‘...")

        # ëª¨ë“  foldì˜ ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
        all_predictions = [fp['predictions'] for fp in fold_predictions]

        # DataFrameì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬
        import pandas as pd

        if isinstance(all_predictions[0], pd.DataFrame):
            # DataFrameì¸ ê²½ìš° summary ì»¬ëŸ¼ ì¶”ì¶œ
            all_summaries = [pred['summary'].tolist() for pred in all_predictions]
            all_fnames = all_predictions[0]['fname'].tolist()  # ì²« ë²ˆì§¸ foldì˜ fname ì‚¬ìš©

            ensemble_predictions = []

            for i in range(len(all_summaries[0])):
                # ê° foldì˜ ië²ˆì§¸ ì˜ˆì¸¡ ìˆ˜ì§‘
                fold_preds_for_sample = [summaries[i] for summaries in all_summaries]

                # ë‹¨ìˆœíˆ ì²« ë²ˆì§¸ foldì˜ ì˜ˆì¸¡ì„ ì‚¬ìš© (í…ìŠ¤íŠ¸ ì•™ìƒë¸”ì˜ ë³µì¡ì„± ë•Œë¬¸)
                # ì‹¤ì œë¡œëŠ” ROUGE ì ìˆ˜ ê¸°ë°˜ ì„ íƒì´ë‚˜ ë‹¤ë¥¸ ë°©ë²• ì‚¬ìš© ê°€ëŠ¥
                ensemble_predictions.append(fold_preds_for_sample[0])

            # DataFrame í˜•íƒœë¡œ ê²°ê³¼ ìƒì„±
            ensemble_df = pd.DataFrame({
                'fname': all_fnames,
                'summary': ensemble_predictions
            })

            return {
                'method': 'voting',
                'predictions': ensemble_df,
                'fold_count': len(fold_predictions),
                'individual_predictions': {
                    f'fold_{fp["fold_num"]}': fp['predictions']
                    for fp in fold_predictions
                }
            }
        else:
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            ensemble_predictions = []

            for i in range(len(all_predictions[0])):
                # ê° foldì˜ ië²ˆì§¸ ì˜ˆì¸¡ ìˆ˜ì§‘
                fold_preds_for_sample = [pred[i] for pred in all_predictions]

                # ë‹¨ìˆœíˆ ì²« ë²ˆì§¸ foldì˜ ì˜ˆì¸¡ì„ ì‚¬ìš©
                ensemble_predictions.append(fold_preds_for_sample[0])

            return {
                'method': 'voting',
                'predictions': ensemble_predictions,
                'fold_count': len(fold_predictions),
                'individual_predictions': {
                    f'fold_{fp["fold_num"]}': fp['predictions']
                    for fp in fold_predictions
                }
            }

    def _weighted_ensemble(self, fold_predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)"""
        logger.info("ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” ìˆ˜í–‰ ì¤‘...")

        # ê° foldì˜ ì„±ëŠ¥ì„ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
        weights = []
        for fp in fold_predictions:
            metric = fp.get('best_metric', 0.0)
            weights.append(max(metric, 0.1))  # ìµœì†Œ ê°€ì¤‘ì¹˜ ë³´ì¥

        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(weights)
        weights = [w / total_weight for w in weights]

        logger.info(f"Foldë³„ ê°€ì¤‘ì¹˜: {[f'{w:.3f}' for w in weights]}")

        # ê°€ì¤‘ì¹˜ê°€ ê°€ì¥ ë†’ì€ foldì˜ ì˜ˆì¸¡ ì‚¬ìš© (í…ìŠ¤íŠ¸ íŠ¹ì„±ìƒ)
        best_fold_idx = np.argmax(weights)
        best_fold_predictions = fold_predictions[best_fold_idx]['predictions']

        return {
            'method': 'weighted',
            'predictions': best_fold_predictions,
            'weights': weights,
            'best_fold': fold_predictions[best_fold_idx]['fold_num'],
            'fold_count': len(fold_predictions)
        }

    def _best_model_ensemble(self, fold_predictions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ"""
        logger.info("ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ì¤‘...")

        # ê°€ì¥ ë†’ì€ ë©”íŠ¸ë¦­ì„ ê°€ì§„ fold ì°¾ê¸°
        best_fold = max(fold_predictions,
                        key=lambda x: x.get('best_metric', 0.0))

        logger.info(
            f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: Fold {best_fold['fold_num']} (ë©”íŠ¸ë¦­: {best_fold['best_metric']:.4f})")

        return {
            'method': 'best',
            'predictions': best_fold['predictions'],
            'best_fold': best_fold['fold_num'],
            'best_metric': best_fold['best_metric'],
            'fold_count': len(fold_predictions)
        }
